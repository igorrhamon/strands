"""
Advanced Confidence Policy - Pol√≠tica de Confian√ßa com Detec√ß√£o de Alucina√ß√£o

Implementa c√°lculo de confian√ßa baseado em Bayesiano com detec√ß√£o autom√°tica
de alucina√ß√µes (diverg√™ncias entre confian√ßa reportada vs calculada).

Padr√£o: Bayesian Inference + Anomaly Detection
Resili√™ncia: Valida√ß√£o de dados, detec√ß√£o de outliers
"""

import logging
from typing import Dict, List, Optional, Tuple
from enum import Enum
from dataclasses import dataclass

from pydantic import BaseModel, Field, validator

logger = logging.getLogger(__name__)


class ConfidenceLevel(str, Enum):
    """N√≠veis de confian√ßa."""
    VERY_LOW = "very_low"          # 0.0 - 0.2
    LOW = "low"                    # 0.2 - 0.4
    MEDIUM = "medium"              # 0.4 - 0.6
    HIGH = "high"                  # 0.6 - 0.8
    VERY_HIGH = "very_high"        # 0.8 - 1.0


class AlucinationSeverity(str, Enum):
    """Severidade de alucina√ß√£o."""
    NONE = "none"                  # Sem alucina√ß√£o
    LOW = "low"                    # Diverg√™ncia < 10%
    MEDIUM = "medium"              # Diverg√™ncia 10-20%
    HIGH = "high"                  # Diverg√™ncia 20-50%
    CRITICAL = "critical"          # Diverg√™ncia > 50%


@dataclass
class BayesianCalculation:
    """C√°lculo bayesiano de confian√ßa."""
    
    prior_probability: float        # P(H) - Probabilidade pr√©via
    likelihood: float               # P(E|H) - Probabilidade da evid√™ncia dado H
    evidence_probability: float     # P(E) - Probabilidade da evid√™ncia
    posterior_probability: float    # P(H|E) - Probabilidade posterior
    
    def to_dict(self) -> Dict:
        """Converte para dicion√°rio."""
        return {
            "prior": self.prior_probability,
            "likelihood": self.likelihood,
            "evidence": self.evidence_probability,
            "posterior": self.posterior_probability,
        }


class ConfidenceCalculation(BaseModel):
    """Resultado do c√°lculo de confian√ßa."""
    
    agent_confidence: float = Field(..., ge=0, le=1, description="Confian√ßa reportada pelo agente")
    evidence_count: int = Field(..., ge=0, description="N√∫mero de evid√™ncias")
    evidence_weight: float = Field(..., ge=0, le=1, description="Peso das evid√™ncias")
    calculated_confidence: float = Field(..., ge=0, le=1, description="Confian√ßa calculada")
    confidence_level: ConfidenceLevel = Field(..., description="N√≠vel de confian√ßa")
    bayesian_calculation: Dict = Field(..., description="C√°lculo bayesiano")
    hallucination_detected: bool = Field(..., description="Alucina√ß√£o detectada?")
    hallucination_severity: AlucinationSeverity = Field(..., description="Severidade da alucina√ß√£o")
    divergence_percentage: float = Field(..., ge=0, le=100, description="Diverg√™ncia em %")
    recommendations: List[str] = Field(..., description="Recomenda√ß√µes")
    
    class Config:
        frozen = True


class AdvancedConfidencePolicy:
    """Pol√≠tica de confian√ßa avan√ßada com detec√ß√£o de alucina√ß√£o.
    
    Responsabilidades:
    1. Calcular confian√ßa usando Bayesiano
    2. Detectar alucina√ß√µes (diverg√™ncias)
    3. Fornecer recomenda√ß√µes
    4. Rastrear padr√µes de alucina√ß√£o
    """
    
    def __init__(self,
                 hallucination_threshold_percentage: float = 20.0,
                 min_evidence_count: int = 2):
        """Inicializa a pol√≠tica.
        
        Args:
            hallucination_threshold_percentage: Threshold de diverg√™ncia para flaggar alucina√ß√£o
            min_evidence_count: N√∫mero m√≠nimo de evid√™ncias
        """
        self.hallucination_threshold = hallucination_threshold_percentage
        self.min_evidence_count = min_evidence_count
        self.logger = logging.getLogger("advanced_confidence_policy")
        self._hallucination_history: List[Dict] = []
    
    def calculate_confidence(self,
                            agent_confidence: float,
                            evidence_count: int,
                            evidence_weight: float = 1.0,
                            agent_id: Optional[str] = None) -> ConfidenceCalculation:
        """Calcula confian√ßa com detec√ß√£o de alucina√ß√£o.
        
        F√≥rmula Bayesiana:
        P(H|E) = P(E|H) * P(H) / P(E)
        
        Onde:
        - H = Hip√≥tese (decis√£o correta)
        - E = Evid√™ncia (dados do agente)
        
        Args:
            agent_confidence: Confian√ßa reportada pelo agente (0-1)
            evidence_count: N√∫mero de evid√™ncias
            evidence_weight: Peso das evid√™ncias (0-1)
            agent_id: ID do agente (para rastreamento)
        
        Returns:
            ConfidenceCalculation
        """
        # Validar entrada
        agent_confidence = max(0, min(1, agent_confidence))
        evidence_weight = max(0, min(1, evidence_weight))
        
        # C√°lculo Bayesiano
        bayesian = self._calculate_bayesian(
            agent_confidence,
            evidence_count,
            evidence_weight
        )
        
        calculated_confidence = bayesian.posterior_probability
        
        # Detectar alucina√ß√£o
        divergence_percentage = abs(agent_confidence - calculated_confidence) * 100
        hallucination_detected = divergence_percentage > self.hallucination_threshold
        hallucination_severity = self._classify_hallucination_severity(divergence_percentage)
        
        # Determinar n√≠vel de confian√ßa
        confidence_level = self._classify_confidence_level(calculated_confidence)
        
        # Gerar recomenda√ß√µes
        recommendations = self._generate_recommendations(
            calculated_confidence,
            confidence_level,
            hallucination_detected,
            hallucination_severity,
            evidence_count
        )
        
        # Rastrear alucina√ß√£o
        if hallucination_detected:
            self._hallucination_history.append({
                "agent_id": agent_id,
                "agent_confidence": agent_confidence,
                "calculated_confidence": calculated_confidence,
                "divergence_percentage": divergence_percentage,
                "severity": hallucination_severity.value,
            })
            
            self.logger.warning(
                f"Alucina√ß√£o detectada [agent={agent_id}]: "
                f"reportada={agent_confidence:.2f}, "
                f"calculada={calculated_confidence:.2f}, "
                f"diverg√™ncia={divergence_percentage:.1f}%"
            )
        
        return ConfidenceCalculation(
            agent_confidence=agent_confidence,
            evidence_count=evidence_count,
            evidence_weight=evidence_weight,
            calculated_confidence=calculated_confidence,
            confidence_level=confidence_level,
            bayesian_calculation=bayesian.to_dict(),
            hallucination_detected=hallucination_detected,
            hallucination_severity=hallucination_severity,
            divergence_percentage=divergence_percentage,
            recommendations=recommendations,
        )
    
    def _calculate_bayesian(self,
                           agent_confidence: float,
                           evidence_count: int,
                           evidence_weight: float) -> BayesianCalculation:
        """Calcula probabilidade bayesiana.
        
        Args:
            agent_confidence: Confian√ßa do agente
            evidence_count: N√∫mero de evid√™ncias
            evidence_weight: Peso das evid√™ncias
        
        Returns:
            BayesianCalculation
        """
        # Prior: Probabilidade pr√©via baseada em hist√≥rico
        prior = 0.5  # Sem informa√ß√£o pr√©via, assume 50%
        
        # Likelihood: P(E|H) - Probabilidade da evid√™ncia dado que H √© verdadeira
        # Aumenta com n√∫mero e peso de evid√™ncias
        likelihood = min(1.0, 0.5 + (evidence_count * 0.15) + (evidence_weight * 0.2))
        
        # Evidence: P(E) - Probabilidade da evid√™ncia
        # Combina likelihood com prior
        evidence = (likelihood * prior) + ((1 - likelihood) * (1 - prior))
        
        # Posterior: P(H|E) - Probabilidade posterior (Bayes' theorem)
        posterior = (likelihood * prior) / evidence if evidence > 0 else 0.5
        
        # Ajustar posterior com confian√ßa do agente
        adjusted_posterior = (posterior * 0.7) + (agent_confidence * 0.3)
        
        return BayesianCalculation(
            prior_probability=prior,
            likelihood=likelihood,
            evidence_probability=evidence,
            posterior_probability=adjusted_posterior,
        )
    
    def _classify_confidence_level(self, confidence: float) -> ConfidenceLevel:
        """Classifica n√≠vel de confian√ßa.
        
        Args:
            confidence: Valor de confian√ßa (0-1)
        
        Returns:
            ConfidenceLevel
        """
        if confidence < 0.2:
            return ConfidenceLevel.VERY_LOW
        elif confidence < 0.4:
            return ConfidenceLevel.LOW
        elif confidence < 0.6:
            return ConfidenceLevel.MEDIUM
        elif confidence < 0.8:
            return ConfidenceLevel.HIGH
        else:
            return ConfidenceLevel.VERY_HIGH
    
    def _classify_hallucination_severity(self, divergence_percentage: float) -> AlucinationSeverity:
        """Classifica severidade de alucina√ß√£o.
        
        Args:
            divergence_percentage: Diverg√™ncia em percentual
        
        Returns:
            AlucinationSeverity
        """
        if divergence_percentage < 1:
            return AlucinationSeverity.NONE
        elif divergence_percentage < 10:
            return AlucinationSeverity.LOW
        elif divergence_percentage < 20:
            return AlucinationSeverity.MEDIUM
        elif divergence_percentage < 50:
            return AlucinationSeverity.HIGH
        else:
            return AlucinationSeverity.CRITICAL
    
    def _generate_recommendations(self,
                                 confidence: float,
                                 confidence_level: ConfidenceLevel,
                                 hallucination_detected: bool,
                                 hallucination_severity: AlucinationSeverity,
                                 evidence_count: int) -> List[str]:
        """Gera recomenda√ß√µes baseadas no c√°lculo.
        
        Args:
            confidence: Confian√ßa calculada
            confidence_level: N√≠vel de confian√ßa
            hallucination_detected: Alucina√ß√£o detectada?
            hallucination_severity: Severidade da alucina√ß√£o
            evidence_count: N√∫mero de evid√™ncias
        
        Returns:
            Lista de recomenda√ß√µes
        """
        recommendations = []
        
        # Recomenda√ß√µes por n√≠vel de confian√ßa
        if confidence_level == ConfidenceLevel.VERY_LOW:
            recommendations.append("üî¥ CONFIAN√áA MUITO BAIXA: Requer revis√£o humana obrigat√≥ria")
        elif confidence_level == ConfidenceLevel.LOW:
            recommendations.append("üü° CONFIAN√áA BAIXA: Recomenda-se revis√£o humana")
        elif confidence_level == ConfidenceLevel.MEDIUM:
            recommendations.append("üü† CONFIAN√áA M√âDIA: Monitorar resultado")
        elif confidence_level == ConfidenceLevel.HIGH:
            recommendations.append("üü¢ CONFIAN√áA ALTA: Pode proceder com monitoramento")
        elif confidence_level == ConfidenceLevel.VERY_HIGH:
            recommendations.append("‚úÖ CONFIAN√áA MUITO ALTA: Pode proceder automaticamente")
        
        # Recomenda√ß√µes por alucina√ß√£o
        if hallucination_detected:
            if hallucination_severity == AlucinationSeverity.CRITICAL:
                recommendations.append("üö® ALUCINA√á√ÉO CR√çTICA: Poss√≠vel falha no agente")
                recommendations.append("‚Üí Verificar logs do agente")
                recommendations.append("‚Üí Considerar retentativa com dados diferentes")
            elif hallucination_severity == AlucinationSeverity.HIGH:
                recommendations.append("‚ö†Ô∏è ALUCINA√á√ÉO ALTA: Diverg√™ncia significativa")
                recommendations.append("‚Üí Investigar discrep√¢ncia")
            elif hallucination_severity == AlucinationSeverity.MEDIUM:
                recommendations.append("‚ö° ALUCINA√á√ÉO M√âDIA: Pequena diverg√™ncia detectada")
                recommendations.append("‚Üí Monitorar padr√£o")
            elif hallucination_severity == AlucinationSeverity.LOW:
                recommendations.append("‚ÑπÔ∏è ALUCINA√á√ÉO BAIXA: Varia√ß√£o normal")
        
        # Recomenda√ß√µes por evid√™ncia
        if evidence_count < self.min_evidence_count:
            recommendations.append(f"üìä EVID√äNCIA INSUFICIENTE: Apenas {evidence_count} evid√™ncia(s)")
            recommendations.append(f"‚Üí Coletar pelo menos {self.min_evidence_count} evid√™ncias")
        
        return recommendations
    
    def get_hallucination_statistics(self) -> Dict:
        """Obt√©m estat√≠sticas de alucina√ß√µes.
        
        Returns:
            Dicion√°rio com estat√≠sticas
        """
        if not self._hallucination_history:
            return {
                "total_hallucinations": 0,
                "by_severity": {},
                "average_divergence": 0,
            }
        
        by_severity = {}
        total_divergence = 0
        
        for record in self._hallucination_history:
            severity = record["severity"]
            by_severity[severity] = by_severity.get(severity, 0) + 1
            total_divergence += record["divergence_percentage"]
        
        return {
            "total_hallucinations": len(self._hallucination_history),
            "by_severity": by_severity,
            "average_divergence": total_divergence / len(self._hallucination_history),
            "critical_count": by_severity.get("critical", 0),
        }
    
    def clear_hallucination_history(self):
        """Limpa hist√≥rico de alucina√ß√µes."""
        self._hallucination_history.clear()
        self.logger.info("Hallucination history cleared")
