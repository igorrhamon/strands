"""
Pol√≠tica de Confian√ßa - C√°lculo Bayesiano de Confian√ßa

Implementa c√°lculo de confian√ßa baseado em densidade de evid√™ncias
com detec√ß√£o de poss√≠vel alucina√ß√£o (diverg√™ncia > 20%).

F√≥rmula:
    final_confidence = (agent_confidence * weight) + (evidence_count * 0.1)

Se |agent_confidence - calculated_confidence| > 0.2:
    Flag como "Potential Hallucination"
"""

import logging
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple
from datetime import datetime
from enum import Enum

from pydantic import BaseModel, Field, validator

logger = logging.getLogger(__name__)


class ConfidenceLevel(str, Enum):
    """N√≠veis de confian√ßa."""
    VERY_LOW = "very_low"      # 0.0 - 0.2
    LOW = "low"                # 0.2 - 0.4
    MEDIUM = "medium"          # 0.4 - 0.6
    HIGH = "high"              # 0.6 - 0.8
    VERY_HIGH = "very_high"    # 0.8 - 1.0


class HallucinationFlag(str, Enum):
    """Tipos de flag de alucina√ß√£o."""
    NO_HALLUCINATION = "no_hallucination"
    POTENTIAL_HALLUCINATION = "potential_hallucination"
    LIKELY_HALLUCINATION = "likely_hallucination"
    CONFIRMED_HALLUCINATION = "confirmed_hallucination"


@dataclass
class EvidenceItem:
    """Representa uma evid√™ncia individual."""
    
    source: str                 # Origem da evid√™ncia (log, m√©trica, etc)
    confidence: float          # Confian√ßa desta evid√™ncia (0.0-1.0)
    weight: float = 1.0        # Peso da evid√™ncia
    description: str = ""      # Descri√ß√£o
    timestamp: datetime = None
    
    def __post_init__(self):
        if not (0.0 <= self.confidence <= 1.0):
            raise ValueError(f"Confian√ßa deve estar entre 0.0 e 1.0, recebido {self.confidence}")
        if self.weight < 0:
            raise ValueError(f"Peso n√£o pode ser negativo, recebido {self.weight}")
        if self.timestamp is None:
            self.timestamp = datetime.utcnow()


class ConfidenceCalculation(BaseModel):
    """Resultado do c√°lculo de confian√ßa."""
    
    final_confidence: float = Field(..., ge=0.0, le=1.0, description="Confian√ßa final calculada")
    agent_reported_confidence: float = Field(..., ge=0.0, le=1.0, description="Confian√ßa reportada pelo agente")
    evidence_count: int = Field(..., ge=0, description="N√∫mero de evid√™ncias")
    evidence_weight_sum: float = Field(..., ge=0.0, description="Soma dos pesos das evid√™ncias")
    confidence_level: ConfidenceLevel = Field(..., description="N√≠vel de confian√ßa")
    hallucination_flag: HallucinationFlag = Field(..., description="Flag de poss√≠vel alucina√ß√£o")
    divergence: float = Field(..., ge=0.0, le=1.0, description="Diverg√™ncia entre reportado e calculado")
    divergence_percentage: float = Field(..., ge=0.0, le=100.0, description="Diverg√™ncia em percentual")
    calculation_details: Dict = Field(default_factory=dict, description="Detalhes do c√°lculo")
    timestamp: datetime = Field(default_factory=datetime.utcnow)
    
    class Config:
        frozen = True


class ConfidencePolicy:
    """Pol√≠tica de c√°lculo de confian√ßa com l√≥gica Bayesiana.
    
    Responsabilidades:
    1. Calcular confian√ßa baseada em evid√™ncias
    2. Detectar poss√≠vel alucina√ß√£o
    3. Validar diverg√™ncia entre reportado e calculado
    4. Gerar recomenda√ß√µes
    """
    
    # Constantes de c√°lculo
    EVIDENCE_WEIGHT_FACTOR = 0.1  # Fator para peso de evid√™ncia
    HALLUCINATION_THRESHOLD = 0.2  # Threshold para diverg√™ncia (20%)
    LIKELY_HALLUCINATION_THRESHOLD = 0.3  # Threshold para alucina√ß√£o prov√°vel (30%)
    
    def __init__(self, base_weight: float = 1.0):
        """Inicializa pol√≠tica.
        
        Args:
            base_weight: Peso base para c√°lculos
        """
        self.base_weight = base_weight
        self.logger = logging.getLogger("confidence_policy")
    
    def calculate_confidence(self, 
                            agent_confidence: float,
                            evidence_items: List[EvidenceItem],
                            context: Optional[Dict] = None) -> ConfidenceCalculation:
        """Calcula confian√ßa usando f√≥rmula Bayesiana.
        
        F√≥rmula:
            final_confidence = (agent_confidence * base_weight) + 
                              (sum(evidence_confidence * evidence_weight) / evidence_count * EVIDENCE_WEIGHT_FACTOR)
        
        Args:
            agent_confidence: Confian√ßa reportada pelo agente (0.0-1.0)
            evidence_items: Lista de evid√™ncias
            context: Contexto adicional
        
        Returns:
            ConfidenceCalculation com resultado detalhado
        """
        if not (0.0 <= agent_confidence <= 1.0):
            raise ValueError(f"agent_confidence deve estar entre 0.0 e 1.0, recebido {agent_confidence}")
        
        # Calcular contribui√ß√£o das evid√™ncias
        evidence_count = len(evidence_items)
        
        if evidence_count == 0:
            # Sem evid√™ncias, usar confian√ßa do agente
            final_confidence = agent_confidence
            evidence_contribution = 0.0
            evidence_weight_sum = 0.0
        else:
            # Calcular m√©dia ponderada das evid√™ncias
            weighted_sum = sum(
                item.confidence * item.weight 
                for item in evidence_items
            )
            weight_sum = sum(item.weight for item in evidence_items)
            
            evidence_average = weighted_sum / weight_sum if weight_sum > 0 else 0.0
            evidence_contribution = evidence_average * self.EVIDENCE_WEIGHT_FACTOR
            evidence_weight_sum = weight_sum
            
            # Aplicar f√≥rmula Bayesiana
            final_confidence = min(
                1.0,  # Capped at 1.0
                (agent_confidence * self.base_weight) + evidence_contribution
            )
        
        # Calcular diverg√™ncia
        divergence = abs(agent_confidence - final_confidence)
        divergence_percentage = divergence * 100.0
        
        # Determinar flag de alucina√ß√£o
        hallucination_flag = self._determine_hallucination_flag(divergence_percentage)
        
        # Determinar n√≠vel de confian√ßa
        confidence_level = self._determine_confidence_level(final_confidence)
        
        # Preparar detalhes do c√°lculo
        calculation_details = {
            "agent_confidence": agent_confidence,
            "evidence_count": evidence_count,
            "evidence_average": evidence_average if evidence_count > 0 else 0.0,
            "evidence_contribution": evidence_contribution,
            "base_weight": self.base_weight,
            "formula": "final_confidence = (agent_confidence * base_weight) + (evidence_average * EVIDENCE_WEIGHT_FACTOR)",
            "evidence_sources": [item.source for item in evidence_items],
        }
        
        # Log
        self.logger.info(
            f"Confian√ßa calculada: final={final_confidence:.3f}, "
            f"reportada={agent_confidence:.3f}, "
            f"diverg√™ncia={divergence_percentage:.1f}%, "
            f"flag={hallucination_flag.value}, "
            f"evid√™ncias={evidence_count}"
        )
        
        return ConfidenceCalculation(
            final_confidence=final_confidence,
            agent_reported_confidence=agent_confidence,
            evidence_count=evidence_count,
            evidence_weight_sum=evidence_weight_sum,
            confidence_level=confidence_level,
            hallucination_flag=hallucination_flag,
            divergence=divergence,
            divergence_percentage=divergence_percentage,
            calculation_details=calculation_details,
        )
    
    def _determine_hallucination_flag(self, divergence_percentage: float) -> HallucinationFlag:
        """Determina flag de alucina√ß√£o baseado em diverg√™ncia.
        
        Args:
            divergence_percentage: Diverg√™ncia em percentual (0-100)
        
        Returns:
            Flag de alucina√ß√£o
        """
        if divergence_percentage < self.HALLUCINATION_THRESHOLD * 100:
            return HallucinationFlag.NO_HALLUCINATION
        elif divergence_percentage < self.LIKELY_HALLUCINATION_THRESHOLD * 100:
            return HallucinationFlag.POTENTIAL_HALLUCINATION
        else:
            return HallucinationFlag.LIKELY_HALLUCINATION
    
    def _determine_confidence_level(self, confidence: float) -> ConfidenceLevel:
        """Determina n√≠vel de confian√ßa.
        
        Args:
            confidence: Score de confian√ßa (0.0-1.0)
        
        Returns:
            N√≠vel de confian√ßa
        """
        if confidence < 0.2:
            return ConfidenceLevel.VERY_LOW
        elif confidence < 0.4:
            return ConfidenceLevel.LOW
        elif confidence < 0.6:
            return ConfidenceLevel.MEDIUM
        elif confidence < 0.8:
            return ConfidenceLevel.HIGH
        else:
            return ConfidenceLevel.VERY_HIGH
    
    def validate_confidence(self, 
                           agent_confidence: float,
                           evidence_items: List[EvidenceItem],
                           context: Optional[Dict] = None) -> Tuple[bool, str]:
        """Valida se confian√ßa √© confi√°vel.
        
        Args:
            agent_confidence: Confian√ßa reportada
            evidence_items: Evid√™ncias
            context: Contexto
        
        Returns:
            Tupla (√©_v√°lida, raz√£o)
        """
        calculation = self.calculate_confidence(agent_confidence, evidence_items, context)
        
        # Verificar alucina√ß√£o
        if calculation.hallucination_flag == HallucinationFlag.LIKELY_HALLUCINATION:
            return False, (
                f"Poss√≠vel alucina√ß√£o detectada: diverg√™ncia de {calculation.divergence_percentage:.1f}% "
                f"entre reportado ({agent_confidence:.3f}) e calculado ({calculation.final_confidence:.3f})"
            )
        
        # Verificar se h√° evid√™ncias suficientes
        if calculation.evidence_count == 0 and agent_confidence < 0.5:
            return False, "Confian√ßa baixa sem evid√™ncias de suporte"
        
        return True, "Confian√ßa validada"
    
    def get_recommendation(self, 
                          calculation: ConfidenceCalculation,
                          context: Optional[Dict] = None) -> str:
        """Gera recomenda√ß√£o baseada no c√°lculo.
        
        Args:
            calculation: Resultado do c√°lculo
            context: Contexto adicional
        
        Returns:
            Recomenda√ß√£o em texto
        """
        recommendations = []
        
        # Baseado no n√≠vel de confian√ßa
        if calculation.confidence_level == ConfidenceLevel.VERY_LOW:
            recommendations.append("‚ö†Ô∏è CONFIAN√áA MUITO BAIXA: Requer revis√£o humana urgente")
        elif calculation.confidence_level == ConfidenceLevel.LOW:
            recommendations.append("‚ö†Ô∏è CONFIAN√áA BAIXA: Recomenda-se revis√£o humana")
        elif calculation.confidence_level == ConfidenceLevel.VERY_HIGH:
            recommendations.append("‚úÖ CONFIAN√áA MUITO ALTA: Pode proceder automaticamente")
        
        # Baseado em alucina√ß√£o
        if calculation.hallucination_flag == HallucinationFlag.LIKELY_HALLUCINATION:
            recommendations.append(
                f"üö® POSS√çVEL ALUCINA√á√ÉO: Diverg√™ncia de {calculation.divergence_percentage:.1f}% "
                f"entre reportado e calculado"
            )
        elif calculation.hallucination_flag == HallucinationFlag.POTENTIAL_HALLUCINATION:
            recommendations.append(
                f"‚ö†Ô∏è POSS√çVEL ALUCINA√á√ÉO: Diverg√™ncia de {calculation.divergence_percentage:.1f}% "
                f"(pr√≥xima ao threshold)"
            )
        
        # Baseado em evid√™ncias
        if calculation.evidence_count == 0:
            recommendations.append("‚ÑπÔ∏è Sem evid√™ncias de suporte: Confian√ßa baseada apenas no agente")
        elif calculation.evidence_count < 3:
            recommendations.append(f"‚ÑπÔ∏è Poucas evid√™ncias ({calculation.evidence_count}): Considere coletar mais dados")
        
        return " | ".join(recommendations) if recommendations else "‚úÖ Sem recomenda√ß√µes especiais"
    
    def batch_calculate(self, 
                       calculations_data: List[Dict]) -> List[ConfidenceCalculation]:
        """Calcula confian√ßa para m√∫ltiplos casos em lote.
        
        Args:
            calculations_data: Lista de dicts com agent_confidence e evidence_items
        
        Returns:
            Lista de ConfidenceCalculation
        """
        results = []
        
        for data in calculations_data:
            agent_confidence = data.get("agent_confidence", 0.0)
            evidence_items = data.get("evidence_items", [])
            context = data.get("context")
            
            try:
                result = self.calculate_confidence(agent_confidence, evidence_items, context)
                results.append(result)
            except Exception as e:
                self.logger.error(f"Erro ao calcular confian√ßa em lote: {e}")
                # Retornar c√°lculo com erro
                results.append(
                    ConfidenceCalculation(
                        final_confidence=0.0,
                        agent_reported_confidence=agent_confidence,
                        evidence_count=0,
                        evidence_weight_sum=0.0,
                        confidence_level=ConfidenceLevel.VERY_LOW,
                        hallucination_flag=HallucinationFlag.CONFIRMED_HALLUCINATION,
                        divergence=1.0,
                        divergence_percentage=100.0,
                        calculation_details={"error": str(e)},
                    )
                )
        
        return results
