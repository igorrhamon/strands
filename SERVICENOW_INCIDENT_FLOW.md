# ğŸ« Fluxo de Incidentes ServiceNow com EmbeddingAgent

## ğŸ“š VisÃ£o Geral

Diferente de **alertas de mÃ©trica** (que sÃ£o numÃ©ricos e estruturados), os **incidentes ServiceNow** sÃ£o **textuais e menos estruturados**. O EmbeddingAgent funciona MELHOR com incidentes porque pode capturar a semÃ¢ntica completa da descriÃ§Ã£o.

```
ALERTA DE MÃ‰TRICA          vs          INCIDENTE SERVICENOW
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"Error rate > 5%"                      "Database connection timeout
(Estruturado)                          causing checkout failures
                                       for 30 minutes. Customers
                                       unable to complete orders."
                                       (Textual, rico em contexto)

Embedding: Simples                     Embedding: Muito mais rico
SemÃ¢ntica: Limitada                    SemÃ¢ntica: Completa
```

---

## ğŸ”„ Fluxo Completo - ServiceNow Incidente

### **Passo 1: Incidente Chega do ServiceNow**

```python
# Incidente criado manualmente por um usuÃ¡rio
incident = {
    "number": "INC0123456",
    "short_description": "Database connection timeout",
    "description": """
    Customers are unable to complete checkout transactions.
    Error message: "Connection timeout to payment database".
    
    Affected services:
    - checkout-service
    - payment-api
    - order-processor
    
    Impact: ~500 customers affected, revenue loss ~$5k/min
    
    Recent changes:
    - Database pool size reduced from 100 to 50 connections
    - New payment validation rules deployed 2 hours ago
    
    Symptoms:
    - 95% of checkout requests failing
    - Database CPU at 85%
    - Connection pool exhausted
    """,
    "severity": "1",  # Critical
    "state": "1",  # New
    "assigned_to": None,
    "created_at": "2026-02-06T12:00:00Z",
    "created_by": "user@company.com",
    "tags": ["database", "payment", "critical"]
}
```

### **Passo 2: AlertCollector Busca no ServiceNow**

```python
# AlertCollectorAgent agora suporta ServiceNow
class AlertCollectorAgent:
    def collect_active_alerts(self) -> List[Alert]:
        # Tenta Prometheus primeiro
        if prometheus_available:
            return self._collect_from_prometheus()
        
        # Tenta Grafana
        if grafana_available:
            return self._collect_from_grafana()
        
        # NEW: Tenta ServiceNow
        if servicenow_available:
            return self._collect_from_servicenow()
    
    def _collect_from_servicenow(self) -> List[Alert]:
        """Coleta incidentes abertos do ServiceNow"""
        
        # Query ServiceNow API
        response = requests.get(
            "https://company.service-now.com/api/now/table/incident",
            params={
                "sysparm_query": "stateIN1,2",  # New, In Progress
                "sysparm_limit": 100
            },
            headers={"Authorization": f"Bearer {token}"}
        )
        
        incidents = response.json()["result"]
        alerts = []
        
        for incident in incidents:
            # Converte incidente ServiceNow para Alert
            alert = Alert(
                timestamp=datetime.fromisoformat(incident["created"]),
                fingerprint=incident["number"],  # INC0123456
                service=self._extract_service(incident),
                severity=self._map_severity(incident["severity"]),
                description=incident["short_description"],
                source=AlertSource.SERVICENOW,
                labels={
                    "incident_number": incident["number"],
                    "assigned_to": incident["assigned_to"],
                    "impact": incident["impact"],
                    "urgency": incident["urgency"],
                    "tags": incident["tags"]
                },
                annotations={
                    "full_description": incident["description"],
                    "created_by": incident["created_by"],
                    "company": incident["company"]
                }
            )
            alerts.append(alert)
        
        return alerts
```

### **Passo 3: AlertNormalizer Padroniza**

```python
# O normalizer agora lida com incidentes textuais
class AlertNormalizerAgent:
    def normalize(self, alerts: List[Alert]) -> List[NormalizedAlert]:
        normalized = []
        
        for alert in alerts:
            # Para incidentes ServiceNow, extrai mais contexto
            if alert.source == AlertSource.SERVICENOW:
                
                # Extrai serviÃ§os mencionados na descriÃ§Ã£o
                services = self._extract_services_from_text(
                    alert.annotations.get("full_description", "")
                )
                
                # Extrai impacto
                impact = self._extract_impact(
                    alert.labels.get("impact", ""),
                    alert.annotations.get("full_description", "")
                )
                
                # Normaliza severidade
                severity = self._normalize_severity(
                    alert.labels.get("urgency", ""),
                    alert.labels.get("impact", "")
                )
                
                norm_alert = NormalizedAlert(
                    timestamp=alert.timestamp,
                    fingerprint=alert.fingerprint,
                    service=services[0] if services else "unknown",
                    severity=severity,
                    description=alert.description,
                    labels={
                        **alert.labels,
                        "affected_services": services,
                        "impact_level": impact,
                        "source_system": "servicenow"
                    },
                    validation_status=ValidationStatus.VALID
                )
                normalized.append(norm_alert)
        
        return normalized
    
    def _extract_services_from_text(self, text: str) -> List[str]:
        """Extrai nomes de serviÃ§os da descriÃ§Ã£o textual"""
        # Usa regex ou NLP para encontrar serviÃ§os mencionados
        services = []
        
        service_patterns = {
            "checkout": r"checkout[-_]?service|checkout\s+system",
            "payment": r"payment[-_]?api|payment\s+service",
            "order": r"order[-_]?processor|order\s+service",
            "database": r"database|db\s+server",
        }
        
        for service, pattern in service_patterns.items():
            if re.search(pattern, text, re.IGNORECASE):
                services.append(service)
        
        return services
    
    def _extract_impact(self, impact_field: str, description: str) -> str:
        """Extrai nÃ­vel de impacto"""
        # Mapeia campo de impacto ServiceNow
        impact_map = {
            "1": "critical",
            "2": "high",
            "3": "medium",
            "4": "low"
        }
        
        # Se nÃ£o tiver, tenta extrair da descriÃ§Ã£o
        if impact_field in impact_map:
            return impact_map[impact_field]
        
        # Busca por palavras-chave
        if any(word in description.lower() for word in 
               ["500 customers", "revenue loss", "all users", "production down"]):
            return "critical"
        
        return "medium"
```

### **Passo 4: AlertCorrelator Agrupa**

```python
# Agrupa incidentes relacionados
class AlertCorrelationAgent:
    def correlate(self, alerts: List[NormalizedAlert]) -> List[AlertCluster]:
        clusters = {}
        
        for alert in alerts:
            # Para incidentes ServiceNow, agrupa por serviÃ§os afetados
            if alert.labels.get("source_system") == "servicenow":
                
                # Chave: lista de serviÃ§os afetados
                affected_services = tuple(sorted(
                    alert.labels.get("affected_services", ["unknown"])
                ))
                key = f"servicenow_{affected_services}"
                
                if key not in clusters:
                    clusters[key] = AlertCluster(
                        cluster_id=uuid4(),
                        service=affected_services[0],
                        cluster_type="INCIDENT_CORRELATION",
                        alerts=[alert]
                    )
                else:
                    clusters[key].alerts.append(alert)
            else:
                # LÃ³gica normal para alertas de mÃ©trica
                key = alert.service
                if key not in clusters:
                    clusters[key] = AlertCluster(...)
                else:
                    clusters[key].alerts.append(alert)
        
        return list(clusters.values())
```

### **Passo 5: EmbeddingAgent - Busca SemÃ¢ntica**

Aqui Ã© onde o embedding brilha para incidentes ServiceNow!

```python
# EmbeddingAgent agora recebe o cluster com incidente
async def analyze_embedding(cluster: AlertCluster) -> SimilarityResult:
    """
    Para incidentes ServiceNow, o embedding Ã© MUITO mais poderoso
    porque captura a semÃ¢ntica completa da descriÃ§Ã£o textual.
    """
    
    # ConstrÃ³i texto rico para embedding
    embedding_text = f"""
    {cluster.description}
    
    Affected services: {', '.join(cluster.labels.get('affected_services', []))}
    Impact: {cluster.labels.get('impact_level', 'unknown')}
    Severity: {cluster.severity}
    
    Full context:
    {cluster.annotations.get('full_description', '')}
    """
    
    # Exemplo real
    embedding_text = """
    Database connection timeout
    
    Customers are unable to complete checkout transactions.
    Error message: "Connection timeout to payment database".
    
    Affected services: checkout-service, payment-api, order-processor
    Impact: critical
    Severity: critical
    
    Full context:
    Customers are unable to complete checkout transactions.
    Error message: "Connection timeout to payment database".
    
    Affected services:
    - checkout-service
    - payment-api
    - order-processor
    
    Impact: ~500 customers affected, revenue loss ~$5k/min
    
    Recent changes:
    - Database pool size reduced from 100 to 50 connections
    - New payment validation rules deployed 2 hours ago
    
    Symptoms:
    - 95% of checkout requests failing
    - Database CPU at 85%
    - Connection pool exhausted
    """
    
    # Gera embedding via Ollama
    embedding_vector = await ollama.embed(embedding_text)
    # [0.156, -0.432, 0.789, ..., 0.234]  (384 dims)
    
    # Busca similares no Qdrant
    similar_results = await qdrant.search(
        collection="incident_decisions",
        vector=embedding_vector,
        top_k=5,
        score_threshold=0.75
    )
    
    return SimilarityResult(
        similar_alerts=similar_results,
        confidence=0.92
    )
```

---

## ğŸ¯ Exemplo PrÃ¡tico - Incidente ServiceNow

### **CenÃ¡rio: Novo Incidente de Timeout de Banco de Dados**

```
TEMPO: 2026-02-06 12:00:00

1. INCIDENTE CRIADO NO SERVICENOW
   â”œâ”€ NÃºmero: INC0123456
   â”œâ”€ TÃ­tulo: "Database connection timeout"
   â”œâ”€ DescriÃ§Ã£o: "Customers unable to checkout... 500 affected..."
   â”œâ”€ Severidade: Critical
   â””â”€ ServiÃ§os: checkout, payment, order-processor

2. ALERT COLLECTOR BUSCA SERVICENOW
   â””â”€ Query: GET /api/now/table/incident?state=1,2
   â””â”€ Retorna: Incidente como Alert

3. ALERT NORMALIZER PADRONIZA
   â”œâ”€ Extrai serviÃ§os: [checkout-service, payment-api, order-processor]
   â”œâ”€ Extrai impacto: "critical" (500 customers, $5k/min loss)
   â”œâ”€ Normaliza severidade: "critical"
   â””â”€ Retorna: NormalizedAlert

4. ALERT CORRELATOR AGRUPA
   â””â”€ Agrupa por serviÃ§os afetados
   â””â”€ Cria cluster: "servicenow_checkout-service_payment-api_order-processor"

5. EMBEDDING AGENT - BUSCA SEMÃ‚NTICA â† AQUI Ã‰ DIFERENTE!
   
   Texto para Embedding:
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ "Database connection timeout                            â”‚
   â”‚                                                          â”‚
   â”‚ Customers are unable to complete checkout transactions. â”‚
   â”‚ Error message: Connection timeout to payment database.  â”‚
   â”‚                                                          â”‚
   â”‚ Affected services: checkout-service, payment-api,       â”‚
   â”‚                    order-processor                       â”‚
   â”‚ Impact: critical                                         â”‚
   â”‚ Severity: critical                                       â”‚
   â”‚                                                          â”‚
   â”‚ Full context:                                            â”‚
   â”‚ ...500 customers affected, revenue loss ~$5k/min...     â”‚
   â”‚ ...Database pool size reduced from 100 to 50...         â”‚
   â”‚ ...New payment validation rules deployed 2 hours ago... â”‚
   â”‚ ...95% of checkout requests failing...                  â”‚
   â”‚ ...Database CPU at 85%...                               â”‚
   â”‚ ...Connection pool exhausted..."                         â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
   Ollama Embedding:
   â””â”€ [0.156, -0.432, 0.789, ..., 0.234]  (384 dims)
   
   Qdrant Search:
   â””â”€ Busca similares em "incident_decisions"
   
   RESULTADOS ENCONTRADOS:
   
   âœ“ Resultado 1 (Similaridade: 0.96)
   â”œâ”€ Incidente HistÃ³rico: "Database pool exhaustion"
   â”œâ”€ Data: 2026-01-28 09:15:00 (1 semana atrÃ¡s)
   â”œâ”€ DescriÃ§Ã£o: "Payment database connection pool exhausted
   â”‚             causing checkout failures. Pool size was
   â”‚             reduced during maintenance."
   â”œâ”€ ResoluÃ§Ã£o: "INCREASE_POOL_SIZE + ROLLBACK_RECENT_CHANGES"
   â”œâ”€ Tempo de ResoluÃ§Ã£o: 15 minutos
   â””â”€ ConfianÃ§a: 0.94
   
   âœ“ Resultado 2 (Similaridade: 0.88)
   â”œâ”€ Incidente HistÃ³rico: "Checkout service timeout"
   â”œâ”€ Data: 2026-01-15 14:30:00 (3 semanas atrÃ¡s)
   â”œâ”€ DescriÃ§Ã£o: "Checkout service unable to connect to
   â”‚             payment database. Timeout errors for all
   â”‚             transactions."
   â”œâ”€ ResoluÃ§Ã£o: "RESTART_PAYMENT_API + INCREASE_TIMEOUT"
   â”œâ”€ Tempo de ResoluÃ§Ã£o: 8 minutos
   â””â”€ ConfianÃ§a: 0.87
   
   âœ“ Resultado 3 (Similaridade: 0.82)
   â”œâ”€ Incidente HistÃ³rico: "Order processor database timeout"
   â”œâ”€ Data: 2026-01-05 11:00:00 (1 mÃªs atrÃ¡s)
   â”œâ”€ DescriÃ§Ã£o: "Order processor unable to write to database.
   â”‚             Connection timeout errors."
   â”œâ”€ ResoluÃ§Ã£o: "SCALE_DATABASE_REPLICAS"
   â”œâ”€ Tempo de ResoluÃ§Ã£o: 25 minutos
   â””â”€ ConfianÃ§a: 0.81

6. DECISION ENGINE UTILIZA RESULTADOS
   â”œâ”€ "Encontrei 3 incidentes similares!"
   â”œâ”€ "O mais similar (96%) foi resolvido com:"
   â”‚  â””â”€ "INCREASE_POOL_SIZE + ROLLBACK_RECENT_CHANGES"
   â”œâ”€ "Tempo de resoluÃ§Ã£o anterior: 15 minutos"
   â””â”€ "Vou recomendar a mesma aÃ§Ã£o"

7. DECISÃƒO FINAL
   â”œâ”€ Action: "INCREASE_POOL_SIZE + ROLLBACK_RECENT_CHANGES"
   â”œâ”€ Confidence: 0.96
   â”œâ”€ Reasoning: "96% similar to incident INC0112345 from
   â”‚             1 week ago. Same symptoms: pool exhaustion
   â”‚             after pool size reduction. Same resolution
   â”‚             worked in 15 minutes."
   â”œâ”€ Estimated Resolution Time: 15 minutes
   â””â”€ Risk Level: LOW

8. HUMAN REVIEW (se necessÃ¡rio)
   â”œâ”€ Se confianÃ§a < 70%: Encaminha para analista
   â”œâ”€ Se confianÃ§a > 70%: Aprova automaticamente
   â””â”€ Neste caso: ConfianÃ§a = 0.96 â†’ APROVA

9. EXECUÃ‡ÃƒO
   â”œâ”€ Aumenta pool de conexÃµes de 50 para 100
   â”œâ”€ Faz rollback das mudanÃ§as de validaÃ§Ã£o
   â”œâ”€ Monitora taxa de sucesso de checkout
   â”œâ”€ Atualiza incidente no ServiceNow
   â””â”€ Registra resoluÃ§Ã£o no histÃ³rico

10. PERSISTÃŠNCIA DO EMBEDDING
    â””â”€ ApÃ³s confirmaÃ§Ã£o, armazena em Qdrant:
       {
           "vector": [0.156, -0.432, 0.789, ..., 0.234],
           "payload": {
               "source_decision_id": "dec-999",
               "source_text": "Database connection timeout...",
               "service": "payment-api",
               "severity": "critical",
               "rules_applied": ["PoolExhaustion", "DatabaseTimeout"],
               "resolution_action": "INCREASE_POOL_SIZE",
               "resolution_time_minutes": 12,
               "human_validator": "analyst-john",
               "created_at": "2026-02-06T12:15:00Z"
           }
       }
```

---

## ğŸ” Por Que Embeddings SÃ£o Melhores para Incidentes

### **Alertas de MÃ©trica**
```
Entrada: "Error rate > 5%"
         â†“
Embedding: Simples
         â†“
Busca: "Procura por 'error rate'" (palavra-chave)
         â†“
Problema: Perde contexto semÃ¢ntico
```

### **Incidentes ServiceNow**
```
Entrada: "Database connection timeout causing checkout failures.
          500 customers affected, revenue loss $5k/min.
          Recent changes: pool size reduced, new validation rules."
         â†“
Embedding: Captura TODA a semÃ¢ntica
         â†“
Busca: Encontra incidentes com MESMA SEMÃ‚NTICA
       (mesmo que use palavras diferentes)
         â†“
Vantagem: Captura contexto completo, causa-raiz, impacto
```

### **Exemplo de SemÃ¢ntica Capturada**

```
Incidente 1: "Database connection pool exhausted"
Incidente 2: "Too many connections to payment database"
Incidente 3: "Connection limit reached on DB server"

Sem Embedding:
â””â”€ Nenhuma correspondÃªncia (palavras diferentes)

Com Embedding:
â””â”€ Todos reconhecidos como SIMILARES (mesma semÃ¢ntica)
```

---

## ğŸ“Š DiferenÃ§as: MÃ©trica vs. Incidente

| Aspecto | Alerta de MÃ©trica | Incidente ServiceNow |
|---------|-------------------|----------------------|
| **Fonte** | Prometheus/Grafana | ServiceNow (manual) |
| **Estrutura** | NumÃ©rica | Textual |
| **Contexto** | Limitado | Rico |
| **Embedding** | Simples | Complexo |
| **Busca** | Palavra-chave | SemÃ¢ntica |
| **PrecisÃ£o** | MÃ©dia | Alta |
| **ReutilizaÃ§Ã£o** | Boa | Excelente |

---

## ğŸ”— IntegraÃ§Ã£o com ServiceNow

### **ConfiguraÃ§Ã£o**

```python
# .env
SERVICENOW_URL=https://company.service-now.com
SERVICENOW_API_KEY=xxx
SERVICENOW_TABLE=incident
SERVICENOW_QUERY=stateIN1,2  # New, In Progress

# Mapeamento de severidade
SERVICENOW_SEVERITY_MAP={
    "1": "critical",
    "2": "high",
    "3": "medium",
    "4": "low"
}
```

### **Fluxo de AtualizaÃ§Ã£o**

```python
# ApÃ³s decisÃ£o, atualiza incidente no ServiceNow
class ServiceNowUpdater:
    def update_incident(self, incident_id: str, decision: Decision):
        """Atualiza incidente com decisÃ£o"""
        
        update_data = {
            "state": "2",  # In Progress
            "assigned_to": "strands-automation",
            "work_notes": f"""
            Strands Decision Engine Analysis:
            
            Recommended Action: {decision.action}
            Confidence: {decision.confidence * 100:.1f}%
            
            Similar Incidents Found: 3
            - Most similar (96%): INC0112345
              Resolution: {decision.action}
              Time to resolve: 15 minutes
            
            Reasoning: {decision.reasoning}
            """,
            "u_strands_decision_id": str(decision.decision_id),
            "u_strands_confidence": decision.confidence
        }
        
        # PATCH /api/now/table/incident/INC0123456
        response = requests.patch(
            f"{SERVICENOW_URL}/api/now/table/incident/{incident_id}",
            json=update_data,
            headers={"Authorization": f"Bearer {token}"}
        )
        
        return response.json()
```

---

## ğŸ’¾ Armazenamento em Qdrant

### **Collection: incident_decisions**

```python
# Estrutura de um ponto armazenado
{
    "id": "vec-incident-001",
    "vector": [0.156, -0.432, 0.789, ..., 0.234],  # 384 dims
    "payload": {
        "source_decision_id": "dec-999",
        "source_incident_id": "INC0123456",
        "source_text": "Database connection timeout causing...",
        
        # Contexto
        "service": "payment-api",
        "severity": "critical",
        "affected_services": ["checkout-service", "payment-api", "order-processor"],
        "impact_level": "critical",
        
        # ResoluÃ§Ã£o
        "resolution_action": "INCREASE_POOL_SIZE",
        "resolution_steps": ["Increase pool from 50 to 100", "Rollback validation rules"],
        "resolution_time_minutes": 12,
        
        # Rastreabilidade
        "human_validator": "analyst-john",
        "created_at": "2026-02-06T12:15:00Z",
        "source_system": "servicenow"
    }
}
```

---

## ğŸš€ Fluxo Resumido - ServiceNow vs. MÃ©trica

### **Alerta de MÃ©trica**
```
Prometheus Alert
    â†“
AlertCollector (query /api/v1/alerts)
    â†“
AlertNormalizer (valida numÃ©ricos)
    â†“
AlertCorrelator (agrupa por serviÃ§o)
    â†“
MetricsAnalysis (analisa tendÃªncia)
    â†“
EmbeddingAgent (busca similares)
    â†“
Decision (aÃ§Ã£o)
```

### **Incidente ServiceNow**
```
ServiceNow Incident (manual)
    â†“
AlertCollector (query /api/now/table/incident)
    â†“
AlertNormalizer (extrai contexto textual)
    â†“
AlertCorrelator (agrupa por serviÃ§os afetados)
    â†“
GraphAnalysis (busca dependÃªncias)
    â†“
EmbeddingAgent (busca similares com SEMÃ‚NTICA RICA)
    â†“
Decision (aÃ§Ã£o baseada em histÃ³rico similar)
```

---

## ğŸ“ˆ Vantagens do Embedding para Incidentes

1. **SemÃ¢ntica Completa**: Captura contexto, causa-raiz, impacto
2. **Flexibilidade**: Funciona com qualquer descriÃ§Ã£o textual
3. **ReutilizaÃ§Ã£o**: Encontra resoluÃ§Ãµes anteriores similares
4. **Aprendizado**: Quanto mais incidentes, melhor a busca
5. **ReduÃ§Ã£o de MTTR**: Reutiliza resoluÃ§Ãµes conhecidas
6. **Qualidade**: DecisÃµes baseadas em histÃ³rico validado

---

## ğŸ¯ Resumo

**Incidentes ServiceNow sÃ£o IDEAIS para EmbeddingAgent porque:**

- âœ… Texto rico em contexto
- âœ… SemÃ¢ntica capturÃ¡vel por LLM
- âœ… HistÃ³rico de resoluÃ§Ãµes reutilizÃ¡vel
- âœ… Busca semÃ¢ntica muito mais eficaz
- âœ… Reduz tempo de resoluÃ§Ã£o (MTTR)
- âœ… Melhora qualidade das decisÃµes

O embedding funciona transformando a descriÃ§Ã£o textual completa em um vetor semÃ¢ntico, permitindo encontrar incidentes similares mesmo com palavras diferentes, mas mesma semÃ¢ntica!
