# üß¨ Guia de Evolu√ß√£o Aut√¥noma - Strands

## Vis√£o Geral

Este documento detalha as novas capacidades de **Evolu√ß√£o Aut√¥noma** do Strands, que permitem ao sistema aprender, adaptar-se e melhorar suas opera√ß√µes de remedia√ß√£o sem interven√ß√£o humana constante.

---

## üì¶ Componentes Implementados

### 1. Integra√ß√£o com GitHub Models
**Arquivo:** `src/llm/provider_factory.py`

Adicionamos suporte nativo ao **GitHub Models** (via Azure AI Inference SDK), permitindo acesso a modelos de ponta (GPT-4o, Phi-3, Llama-3) diretamente atrav√©s da infraestrutura do GitHub.

**Configura√ß√£o:**
```bash
export LLM_PROVIDER=github
export LLM_API_KEY=ghp_...
export LLM_MODEL=gpt-4o
```

### 2. Dashboard de Cura√ß√£o SRE
**Frontend:** `frontend/curation_dashboard.html`
**Backend:** `src/api/curation_api.py`

Interface visual para Engenheiros de Confiabilidade (SREs) revisarem, aprovarem ou rejeitarem playbooks gerados por IA.

**Funcionalidades:**
- Listagem de playbooks pendentes (PENDING_REVIEW)
- Visualiza√ß√£o detalhada de passos e comandos
- Avalia√ß√£o de risco (Low, Medium, High)
- Aprova√ß√£o com um clique (move para ACTIVE)
- Rejei√ß√£o com feedback (move para ARCHIVED)

### 3. Feedback Loop & An√°lise de Tend√™ncias
**Arquivo:** `src/core/feedback_loop.py`

Motor que fecha o ciclo de aprendizado:
1. **Coleta:** Registra sucesso/falha de cada execu√ß√£o
2. **An√°lise:** Calcula taxas de sucesso e dura√ß√£o m√©dia
3. **Tend√™ncias:** Identifica padr√µes emergentes (ex: aumento de falhas de mem√≥ria)
4. **Otimiza√ß√£o:** Sugere melhorias em playbooks com desempenho degradado

### 4. Versionamento de Playbooks
**Arquivo:** `src/core/playbook_versioning.py`

Sistema robusto de versionamento sem√¢ntico para playbooks:
- **Major:** Mudan√ßas incompat√≠veis ou reescrita
- **Minor:** Adi√ß√£o de passos ou melhorias
- **Patch:** Corre√ß√µes de bugs ou typos

Permite rollback seguro e rastreabilidade completa de mudan√ßas.

---

## üîÑ Fluxo de Trabalho Completo

1. **Detec√ß√£o:** Correlator detecta um padr√£o de incidente.
2. **Gera√ß√£o:** Se n√£o houver playbook, LLM (GitHub Models) gera um rascunho.
3. **Cura√ß√£o:** SRE acessa o Dashboard e aprova o rascunho.
4. **Execu√ß√£o:** Strands executa o playbook aprovado.
5. **Feedback:** Resultado √© registrado pelo Feedback Loop.
6. **Evolu√ß√£o:** Se a taxa de sucesso cair, o sistema sugere uma nova vers√£o.

---

## üöÄ Como Usar

### Iniciar o Dashboard
```bash
uvicorn src.api.curation_api:app --reload
# Acessar http://localhost:8000/docs para API
# Abrir frontend/curation_dashboard.html no navegador
```

### Configurar GitHub Models
```python
from src.llm.provider_factory import LLMFactory, LLMConfig, LLMProviderType

config = LLMConfig(
    provider=LLMProviderType.GITHUB,
    api_key="seu-token-github",
    model="gpt-4o"
)
provider = LLMFactory.create_provider(config)
response = await provider.generate("Como corrigir OOM no Kubernetes?")
```

---

## üìä M√©tricas de Sucesso

O sistema agora rastreia:
- **Taxa de Automa√ß√£o:** % de incidentes resolvidos sem humano
- **Tempo de Cura√ß√£o:** Tempo m√©dio entre gera√ß√£o e aprova√ß√£o
- **Efic√°cia de Playbook:** Taxa de sucesso por vers√£o
- **Economia de Tempo:** Horas de engenharia salvas

---

**Status:** üü¢ PRONTO PARA PRODU√á√ÉO
